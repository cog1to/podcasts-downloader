#!/usr/bin/env python

import json
import configparser
import optparse
import os
import urllib.request
import sys
import ssl
import xml.etree.ElementTree as ET
from urllib.parse import urlparse, quote
from email.utils import parsedate

# Utils

def error(text):
    """Prints and error message and terminates the application"""
    print(text)
    quit()

def printSkip(episode):
    """Prints formatted 'Skipping...' message for an episode"""
    title = episode.title
    if len(title) >= 53:
        title = title[:50] + "..."
    print("  Episode '{}' exists, skipping".format(title))

def printDownload(episode):
    """Prints formatted 'Downloading...' message for an episode"""
    title = episode.title
    if len(title) >= 53:
        title = title[:50] + "..."
    print(
        "  Downloading '{}'... ".format(title),
        end = '',
        flush = True
    )

# Feed handling

class Episode:
    """Episode info container"""
    def __init__(
        self,
        title = "",
        url = "",
        size = 0,
        date = None,
        number = 0,
        season = 0
    ):
        self.title = title
        self.url = url
        self.size = size
        self.date = date
        self.number = number
        self.season = season

class Feed:
    """Feed info container"""
    def __init__(self, alias, section):
        self.title = section["title"]
        self.alias = alias
        self.path = os.path.expanduser(os.path.expandvars(section["path"]))
        self.url = section["url"]
        self.format = section["file-format"] if "file-format" in section else None
        self.maxEpisodes = int(section["max-episodes"]) if "max-episodes" in section else None
        self.auto = section["auto"] if "auto" in section else True

def prepareFeed(path):
    """Creates a destination directory"""
    if os.path.isdir(path):
        return
    os.makedirs(path)

def fetchFeed(path, url):
    """Downloads a feed from given URL and saves is to the given path"""
    if not os.path.isdir(path):
        error("Feed path doesn't exist")
    destPath = path + "/feed.xml"
    return downloadFile(url, destPath, False)

def downloadFile(url, destPath, verifySize):
    """Downloads a file from given URL and saves is to the given path"""
    # Pretend we're not a robot.
    headers = {"User-Agent": "Mozilla/5.0 (X11; Linux x86_64; rv:136.0) Gecko/20100101 Firefox/136.0"}
    destFile = None
    # Download file.
    try:
        req = urllib.request.Request(url, headers = headers)
        response = urllib.request.urlopen(req, context = ssl._create_unverified_context())
        # Check response length. If it's present, we can do fancy progress stuff
        length = response.getheader('content-length')
        first = True
        if length:
            # Check size
            if os.path.isfile(destPath) and verifySize:
                existingSize = os.path.getsize(destPath)
                if existingSize == int(length):
                    response.close()
                    return True
            # Chunked download for reporing intermediate progress
            destFile = open(destPath, "wb")
            size = 0
            while True:
                buffer = response.read(1 * 1024 * 1024)
                if not buffer:
                    break
                size += len(buffer)
                percent = int(100 * size / int(length))
                destFile.write(buffer)
                if first:
                    print("%2d%% " % percent, end='', flush=True)
                    first = False
                else:
                    print("\033[4D%2d%% " % percent, end='', flush=True)
            response.close()
        else:
            destFile = open(destPath, "wb")
            destFile.write(response.read())
            response.close()
        return True
    except Exception as e:
        print(e)
        if destFile != None:
            destFile.close()
            os.remove(destPath)
        return False

def getEpisodes(feedPath, count):
    """Parses RSS feed and returns `count` number of most recent episodes"""
    feedTree = ET.parse(feedPath)
    rss = feedTree.getroot()
    if rss.tag != "rss":
        error(
            "Bad feed format: expecting <rss> as root element, got {}".format(
                root.tag
            )
        )
    channel = rss.find("channel")
    # Parse items
    items = []
    for child in channel:
        if child.tag != "item":
            continue
        item = Episode()
        for field in child:
            if field.tag == "title":
                item.title = field.text
            if field.tag == "enclosure":
                item.url = field.get("url")
                item.size = int(field.get("length"))
            if field.tag == "pubDate":
                item.date = parsedate(field.text)
            if field.tag == "{http://www.itunes.com/dtds/podcast-1.0.dtd}episode":
                item.number = int(field.text)
            if field.tag == "{http://www.itunes.com/dtds/podcast-1.0.dtd}season":
                item.season = int(field.text)
        items.append(item)
        if count > 0 and len(items) == count:
            break
    return items

def formatEpisode(episode, fileFormat):
    """Produces file name from episode data"""
    # Use default file format.
    if fileFormat == None:
        fileFormat = "{pub} - {title}.mp3"
    fileName = fileFormat
    # Replace placeholders with data.
    # Supported placeholders:
    #   {pub} - publication date
    #   {title} - episode title
    #   {season} - season number
    #   {file} - filename (extracted from the URL)
    if "{pub}" in fileFormat:
        pubDate = "{}-{:02}-{:02}".format(
            episode.date[0],
            episode.date[1],
            episode.date[2]
        )
        fileName = fileName.replace("{pub}", pubDate)
    if "{title}" in fileFormat:
        # Sanitize file name. Useful for compatibility with old filesystems.
        sanitized = sanitize(episode.title)
        fileName = fileName.replace("{title}", sanitized)
    if "{episode}" in fileFormat:
        fileName = fileName.replace(
            "{episode}",
            "{:04}".format(episode.number)
        )
    if "{season}" in fileFormat:
        fileName = fileName.replace(
            "{season}",
            "{:02}".format(episode.season)
        )
    if "{file}" in fileFormat:
        parsedUrl = urlparse(episode.url)
        # Sanitize file name. Useful for compatibility with old filesystems.
        file = sanitize(parsedUrl.path.rsplit("/", 1)[-1])
        fileName = fileName.replace("{file}", file)
    return fileName

def sanitize(value):
    return value.replace("/", "_") \
        .replace("\\", "_") \
        .replace(":", "_") \
        .replace("&", "_") \
        .replace("%", "_") \
        .replace("$", "_") \
        .replace("@", "_") \
        .replace("?", "_") \
        .replace("!", "_") \
        .replace(",", "_") \
        .replace(";", "_") \
        .replace("«", "_") \
        .replace("»", "_") \
        .replace("|", "_") \
        .replace("“", "_") \
        .replace("”", "_") \
        .replace("\"", "_") \

def downloadEpisode(basePath, episode, fileFormat):
    """Checks if episode was already synced and downloads it if necessary"""
    directory = basePath
    if not os.path.isdir(directory):
        error("Target folder '{}' doesn't exist", directory)
    # Get destination path
    parsedUrl = urlparse(episode.url)
    basename = formatEpisode(episode, fileFormat)
    destPath = "{}/{}".format(directory, basename)
    # Check if file exists and has the expected size
    if os.path.exists(destPath):
        if episode.size == 0 or os.path.getsize(destPath) == episode.size:
            printSkip(episode)
            return
    # (re)Download file
    printDownload(episode)
    result = downloadFile(episode.url, destPath, True)
    print("Done" if result == True else "Failed")

# Search

class SearchItem:
    def __init__(self, title, feed):
        self.title = title
        self.feed = feed

def searchPodcasts(term):
    """Performs a search request to iTunes search engine parses the results"""
    escapedTerm = quote(term, encoding = None, errors = None)
    url = "https://itunes.apple.com/search?term={}&entity=podcast".format(
        escapedTerm
    )
    try:
        headers = {"User-Agent": "curl/8.2.1"}
        req = urllib.request.Request(url, headers = headers)
        response = urllib.request.urlopen(req)
        result = json.loads(response.read())

        items = []
        for item in result["results"]:
            items.append(
                SearchItem(item["trackName"], item["feedUrl"])
            )
        return items
    except Exception as e:
        error("Search request failed: {}".format(e))

def performSearch(term):
    """Performs a podcast search and prints the results"""
    items = searchPodcasts(term)
    for item in items:
        print("{}\n  {}".format(item.title, item.feed))

# Config handling

class Config:
    """Config data holder"""
    def __init__(self, config):
        if "default" in config:
            self.maxEpisodes = int(config["default"]["max-episodes"])
        # Parse feeds
        feedNames = filter(lambda s: s != 'default', config.sections())
        self.feeds = list(map(lambda f: Feed(f, config[f]), feedNames))

# Paths to check for config file.
PATHS_TO_CONFIG = [
    "./config",
    "$XDG_CONFIG_HOME/podcasts/config",
    "$HOME/.podcasts"
]

def readConfig(filepath=None):
    """Reads and parses a config file"""
    path = findConfig(filepath, PATHS_TO_CONFIG)
    # Read file
    parser = configparser.ConfigParser()
    parser.read(path)
    # Parse and return
    return Config(parser)

def findConfig(override, paths):
    """Tries to find and read the config file"""
    # Check CLI argument first.
    if override is not None: 
        if os.path.exists(override):
            return override
        else:
            print("Error: config file '%s' does not exist" % override)
            quit()
    # Check default locations.
    for path in paths:
        extended = os.path.expanduser(os.path.expandvars(path))
        if os.path.exists(extended):
            return extended
    # No config found, terminate.
    error("No valid config found")

# Main

usage="%prog [options] OR %prog PODCAST [TERM]"
description="If no podcast name is provided, updates all \"auto\" feeds. Otherwise updates only the specified podcast. If term is provided, downloads episodes from the podcast containing given term."
parser = optparse.OptionParser(usage=usage, description=description)
parser.add_option("-c", dest="config", metavar="FILE", help="use provided config file FILE")
parser.add_option("-l", dest="list", action="store_true", help="list known podcasts")
parser.add_option("-s", dest="search", metavar="TERM", help="do iTunes search for the podcast name")
opts, args = parser.parse_args()

if opts.list:
    config = readConfig(opts.config)
    for feed in config.feeds:
        print("{} - {} - {}".format(feed.alias, feed.title, feed.url))
    quit()

if opts.search:
    if len(sys.argv) < 3:
        error("usage: podcasts -s <search-term>")
    performSearch(opts.search)
    quit()

if True:
    config = readConfig(opts.config)
    for feed in config.feeds:
        # Update feed if no podcast name was specified or if argument matches
        # this podcast name.
        if ((len(args) > 0 and feed.alias == args[0]) or
            (len(args) == 0 and feed.auto == True)):
            print("Fetching feed '{}'... ".format(feed.title), end = '', flush = True)
            prepareFeed(feed.path)
            fetched = fetchFeed(feed.path, feed.url)
            if fetched == True:
                print("Done")
                # Get max episode count.
                # Only limit the number of episodes for regular feed updates.
                count = 0
                if len(args) < 2:
                    count = feed.maxEpisodes if feed.maxEpisodes != None else config.maxEpisodes
                # Get list of episodes.
                episodes = getEpisodes(feed.path + "/feed.xml", count)
                for ep in episodes:
                    # Download the episode if we're updating the whole feed
                    # or if it matches given episode search term.
                    if ((len(args) < 2) or (args[1] in ep.title)):
                        downloadEpisode(feed.path, ep, feed.format)
            else:
                print("Failed, skipping")
    quit()

