#!/usr/bin/env python

import json
import os
import urllib.request
import sys
import xml.etree.ElementTree as ET
from urllib.parse import urlparse, quote
from email.utils import parsedate

# Utils

def error(text):
    """Prints and error message and terminates the application"""
    print(text)
    quit()

def printSkip(episode):
    """Prints formatted 'Skipping...' message for an episode"""
    title = episode.title
    if len(title) >= 53:
        title = title[:50] + "..."
    print("  Episode '{}' exists, skipping".format(title))

def printDownload(episode):
    """Prints formatted 'Downloading...' message for an episode"""
    title = episode.title
    if len(title) >= 53:
        title = title[:50] + "..."
    print(
        "  Downloading '{}'... ".format(title),
        end = '',
        flush = True
    )

# Feed handling

class Episode:
    """Episode info container"""
    def __init__(
        self,
        title = "",
        url = "",
        size = 0,
        date = None,
        number = 0,
        season = 0
    ):
        self.title = title
        self.url = url
        self.size = size
        self.date = date
        self.number = number
        self.season = season

class Feed:
    """Feed info container"""
    def __init__(self, json):
        self.title = json["title"]
        self.alias = json["alias"]
        self.path = os.path.expanduser(os.path.expandvars(json["path"]))
        self.url = json["url"]
        self.format = json["file-format"] if "file-format" in json else None
        self.maxEpisodes = json["max-episodes"] if "max-episodes" in json else None
        self.auto = json["auto"] if "auto" in json else True

def prepareFeed(path):
    """Creates a destination directory"""
    if os.path.isdir(path):
        return
    os.makedirs(path)

def fetchFeed(path, url):
    """Downloads a feed from given URL and saves is to the given path"""
    if not os.path.isdir(path):
        error("Feed path doesn't exist")
    destPath = path + "/feed.xml"
    return downloadFile(url, destPath, False)

def downloadFile(url, destPath, verifySize):
    """Downloads a file from given URL and saves is to the given path"""
    # Pretend we're not a robot.
    headers = {"User-Agent": "curl/8.2.1"}
    # Download file.
    try:
        req = urllib.request.Request(url, headers = headers)
        response = urllib.request.urlopen(req)
        # Check response length. If it's present, we can do fancy progress stuff
        length = response.getheader('content-length')
        first = True
        if length:
            # Check size
            if os.path.isfile(destPath) and verifySize:
                existingSize = os.path.getsize(destPath)
                if existingSize == int(length):
                    response.close()
                    return True
            # Chunked download for reporing intermediate progress
            destFile = open(destPath, "wb")
            size = 0
            while True:
                buffer = response.read(1 * 1024 * 1024)
                if not buffer:
                    break
                size += len(buffer)
                percent = int(100 * size / int(length))
                destFile.write(buffer)
                if first:
                    print("%2d%% " % percent, end='', flush=True)
                    first = False
                else:
                    print("\033[4D%2d%% " % percent, end='', flush=True)
            response.close()
        else:
            destFile = open(destPath, "wb")
            destFile.write(response.read())
            response.close()
        return True
    except Exception as e:
        print(e)
        if destFile != None:
            destFile.close()
            os.remove(destPath)
        return False

def getEpisodes(feedPath, count):
    """Parses RSS feed and returns `count` number of most recent episodes"""
    feedTree = ET.parse(feedPath)
    rss = feedTree.getroot()
    if rss.tag != "rss":
        error(
            "Bad feed format: expecting <rss> as root element, got {}".format(
                root.tag
            )
        )
    channel = rss.find("channel")
    # Parse items
    items = []
    for child in channel:
        if child.tag != "item":
            continue
        item = Episode()
        for field in child:
            if field.tag == "title":
                item.title = field.text
            if field.tag == "enclosure":
                item.url = field.get("url")
                item.size = int(field.get("length"))
            if field.tag == "pubDate":
                item.date = parsedate(field.text)
            if field.tag == "{http://www.itunes.com/dtds/podcast-1.0.dtd}episode":
                item.number = int(field.text)
            if field.tag == "{http://www.itunes.com/dtds/podcast-1.0.dtd}season":
                item.season = int(field.text)
        items.append(item)
        if count > 0 and len(items) == count:
            break
    return items

def formatEpisode(episode, fileFormat):
    """Produces file name from episode data"""
    # Use default file format.
    if fileFormat == None:
        fileFormat = "{pub} - {title}.mp3"
    fileName = fileFormat
    # Replace placeholders with data.
    # Supported placeholders:
    #   {pub} - publication date
    #   {title} - episode title
    #   {season} - season number
    #   {file} - filename (extracted from the URL)
    if "{pub}" in fileFormat:
        pubDate = "{}-{:02}-{:02}".format(
            episode.date[0],
            episode.date[1],
            episode.date[2]
        )
        fileName = fileName.replace("{pub}", pubDate)
    if "{title}" in fileFormat:
        # Sanitize file name. Useful for compatibility with old filesystems.
        sanitized = sanitize(episode.title)
        fileName = fileName.replace("{title}", sanitized)
    if "{episode}" in fileFormat:
        fileName = fileName.replace(
            "{episode}",
            "{:04}".format(episode.number)
        )
    if "{season}" in fileFormat:
        fileName = fileName.replace(
            "{season}",
            "{:02}".format(episode.season)
        )
    if "{file}" in fileFormat:
        parsedUrl = urlparse(episode.url)
        # Sanitize file name. Useful for compatibility with old filesystems.
        file = sanitize(parsedUrl.path.rsplit("/", 1)[-1])
        fileName = fileName.replace("{file}", file)
    return fileName

def sanitize(value):
    return value.replace("/", "_") \
        .replace("\\", "_") \
        .replace(":", "_") \
        .replace("&", "_") \
        .replace("%", "_") \
        .replace("$", "_") \
        .replace("@", "_") \
        .replace("?", "_") \
        .replace("!", "_") \
        .replace(",", "_") \
        .replace(";", "_") \
        .replace("«", "_") \
        .replace("»", "_") \
        .replace("\"", "_") \

def downloadEpisode(basePath, episode, fileFormat):
    """Checks if episode was already synced and downloads it if necessary"""
    directory = basePath
    if not os.path.isdir(directory):
        error("Target folder '{}' doesn't exist", directory)
    # Get destination path
    parsedUrl = urlparse(episode.url)
    basename = formatEpisode(episode, fileFormat)
    destPath = "{}/{}".format(directory, basename)
    # Check if file exists and has the expected size
    if os.path.exists(destPath):
        if episode.size == 0 or os.path.getsize(destPath) == episode.size:
            printSkip(episode)
            return
    # (re)Download file
    printDownload(episode)
    result = downloadFile(episode.url, destPath, True)
    print("Done" if result == True else "Failed")

# Search

class SearchItem:
    def __init__(self, title, feed):
        self.title = title
        self.feed = feed

def searchPodcasts(term):
    """Performs a search request to iTunes search engine parses the results"""
    escapedTerm = quote(term, encoding = None, errors = None)
    url = "https://itunes.apple.com/search?term={}&entity=podcast".format(
        escapedTerm
    )
    try:
        headers = {"User-Agent": "curl/8.2.1"}
        req = urllib.request.Request(url, headers = headers)
        response = urllib.request.urlopen(req)
        result = json.loads(response.read())

        items = []
        for item in result["results"]:
            items.append(
                SearchItem(item["trackName"], item["feedUrl"])
            )
        return items
    except Exception as e:
        error("Search request failed: {}".format(e))

def performSearch(term):
    """Performs a podcast search and prints the results"""
    items = searchPodcasts(term)
    for item in items:
        print("{}\n  {}".format(item.title, item.feed))

# Config handling

class Config:
    """Config data holder"""
    def __init__(self, json):
        self.maxEpisodes = int(json["max-episodes"])
        # Parse feeds
        feeds = []
        feedsJson = json["feeds"]
        for feed in feedsJson:
            feeds.append(Feed(feed))
        self.feeds = feeds


# Paths to check for config file.
PATHS_TO_CONFIG = [
    "./config",
    "$XDG_CONFIG_HOME/podcasts/config",
    "$HOME/.podcasts"
]

def readConfig():
    """Reads and parses a config file"""
    path = findConfig(PATHS_TO_CONFIG)
    # Read file
    configFile = open(path)
    configJson = json.load(configFile)
    configFile.close()
    # Parse and return
    return Config(configJson)

def findConfig(paths):
    """Tries to find and read the config file"""
    # Check CLI argument first.
    if len(sys.argv) > 1 and os.path.exists(sys.argv[-1]):
        return sys.argv[-1]
    # Check default locations.
    for path in paths:
        extended = os.path.expanduser(os.path.expandvars(path))
        if os.path.exists(extended):
            return extended
    # No config found, terminate.
    error("No valid config found")

# Main

if len(sys.argv) > 1 and sys.argv[1] == "-h":
    usage = [
        [
            "usage:"
        ],
        [
            "%s" % (sys.argv[0]),
            "download feeds and episodes for all podcasts"
        ],
        [
            "%s <podcast>" % (sys.argv[0]),
            "download feed and episodes for a specified podcast"
        ],
        [
            "%s <podcast> <term>" % (sys.argv[0]),
            "downloads an episode matching given <term> from <podcast>"
        ],
        [
            "%s -s <search-term>" % (sys.argv[0]),
            "do iTunes search for the podcast name"
        ],
        [
            "%s -l" % (sys.argv[0]),
            "prints friendly-formatted list of podcasts read from config file"
        ],
        [
            "%s -h" % (sys.argv[0]),
            "display this message"
        ],
    ]
    print("\n  ".join([" -- ".join(a) for a in usage]))
    quit()

if len(sys.argv) > 1 and sys.argv[1] == "-l":
    config = readConfig()
    for feed in config.feeds:
        print("{} - {} - {}".format(feed.alias, feed.title, feed.url))
    quit()

if len(sys.argv) > 1 and sys.argv[1] == "-s":
    if len(sys.argv) < 3:
        error("usage: podcasts -s <search-term>")
    performSearch(sys.argv[2])
    quit()

if len(sys.argv) == 1 or sys.argv[1] != "-s":
    config = readConfig()
    for feed in config.feeds:
        # Update feed if no podcast name was specified or if argument matches
        # this podcast name.
        if ((len(sys.argv) > 1 and feed.alias == sys.argv[1]) or
            (len(sys.argv) == 1 and feed.auto == True)):
            print("Fetching feed '{}'... ".format(feed.title), end = '', flush = True)
            prepareFeed(feed.path)
            fetched = fetchFeed(feed.path, feed.url)
            if fetched == True:
                print("Done")
                # Get max episode count.
                # Only limit the number of episodes for regular feed updates.
                count = 0
                if len(sys.argv) < 3:
                    count = feed.maxEpisodes if feed.maxEpisodes != None else config.maxEpisodes
                # Get list of episodes.
                episodes = getEpisodes(feed.path + "/feed.xml", count)
                for ep in episodes:
                    # Download the episode if we're updating the whole feed
                    # or if it matches given episode search term.
                    if ((len(sys.argv) < 3) or (sys.argv[2] in ep.title)):
                        downloadEpisode(feed.path, ep, feed.format)
            else:
                print("Failed, skipping")
    quit()

